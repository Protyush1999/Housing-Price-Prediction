{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libaries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import pylab\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression import linear_model\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "\n",
    "data = pd.read_csv(\"Housing Data 3.csv\")\n",
    "data\n",
    "data1 = data.drop(\"Localities\" , axis = 1)\n",
    "data1\n",
    "\n",
    "data1.info()\n",
    "\n",
    "data1.head()\n",
    "\n",
    "data1.describe()\n",
    "\n",
    "x1 = data1[\"No. of metro stations\"]\n",
    "x2 = data1[\"No. of railway stations(<12kms)\"]\n",
    "x3 = data1[\"No of bus stoppages\"]\n",
    "x4 = data1[\"Distance from the Airport(kms)\"]\n",
    "x5 = data1[\"No of health care centers(Hospitals/Pharmacy)\"]\n",
    "x6 = data1[\"No of Educational Institutes\"]\n",
    "x7 = data1[\"No of Departmental Stores\"]\n",
    "x8 = data1[\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\"]\n",
    "x9 = data1[\"No of Restaurants\"]\n",
    "x10 = data1[\"No of Office\"]\n",
    "x11 = data1[\"No Religious Places(Temples/Mosques)\"]\n",
    "x12 = data1[\"No of Banks/ATMS\"]\n",
    "y = data1[\"Avg Price per sqft (in Rs.)\"]\n",
    "\n",
    "x = data1.drop(\"Avg Price per sqft (in Rs.)\" , axis = 1)\n",
    "x = x.astype(int)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DENSITY PLOT OF X\n",
    "\n",
    "fig, axs = plt.subplots(2,6, figsize=(20,6))\n",
    "\n",
    "sns.distplot(x1, ax=axs[0][0])\n",
    "axs[0][0].set_title(\"Density plot of X1\")\n",
    "\n",
    "sns.distplot(x2, ax=axs[0][1])\n",
    "axs[0][1].set_title(\"Density plot of X2\")\n",
    "\n",
    "sns.distplot(x3, ax=axs[0][2])\n",
    "axs[0][2].set_title(\"Density plot of X3\")\n",
    "\n",
    "sns.distplot(x4, ax=axs[0][3])\n",
    "axs[0][3].set_title(\"Density plot of X4\")\n",
    "\n",
    "sns.distplot(x5, ax=axs[0][4])\n",
    "axs[0][4].set_title(\"Density plot of X5\")\n",
    "\n",
    "sns.distplot(x6, ax=axs[0][5])\n",
    "axs[0][5].set_title(\"Density plot of X6\")\n",
    "\n",
    "sns.distplot(x7, ax=axs[1][0])\n",
    "axs[1][0].set_title(\"Density plot of X7\")\n",
    "\n",
    "sns.distplot(x8, ax=axs[1][1])\n",
    "axs[1][1].set_title(\"Density plot of X8\")\n",
    "\n",
    "sns.distplot(x9, ax=axs[1][2])\n",
    "axs[1][2].set_title(\"Density plot of X9\")\n",
    "\n",
    "sns.distplot(x10, ax=axs[1][3])\n",
    "axs[1][3].set_title(\"Density plot of X10\")\n",
    "\n",
    "sns.distplot(x11, ax=axs[1][4])\n",
    "axs[1][4].set_title(\"Density plot of X11\")\n",
    "\n",
    "sns.distplot(x12, ax=axs[1][5])\n",
    "axs[1][5].set_title(\"Density plot of X12\")\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALITY CHECKING USING SHAPIRO WILK TEST\n",
    "\n",
    "stat1 , pvalue1 = scipy.stats.shapiro(x1)\n",
    "print(stat1)\n",
    "print(pvalue1)\n",
    "\n",
    "if pvalue1<=0.05:\n",
    "    print(\"our data does not follow normal distribution\")\n",
    "else:\n",
    "    print(\"our data follows normal distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ PLOT\n",
    "\n",
    "for i in x:\n",
    "    print(x[i])\n",
    "    scipy.stats.probplot(x[i] , dist = \"norm\" , plot = pylab)\n",
    "\n",
    "scipy.stats.probplot(x1 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x2 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x3 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x4 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x5 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x6 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x7 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x8 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x9 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x10 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x11 , dist = \"norm\" , plot = pylab)\n",
    "scipy.stats.probplot(x12 , dist = \"norm\" , plot = pylab)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOXPLOT\n",
    "\n",
    "fig, axs = plt.subplots(2,6, figsize=(20,6))\n",
    "\n",
    "sns.boxplot(x1, ax=axs[0][0])\n",
    "axs[0][0].set_title(\"Box plot of X1\")\n",
    "\n",
    "sns.boxplot(x2, ax=axs[0][1])\n",
    "axs[0][1].set_title(\"Box plot of X2\")\n",
    "\n",
    "sns.boxplot(x3, ax=axs[0][2])\n",
    "axs[0][2].set_title(\"Box plot of X3\")\n",
    "\n",
    "sns.boxplot(x4, ax=axs[0][3])\n",
    "axs[0][3].set_title(\"Box plot of X4\")\n",
    "\n",
    "sns.boxplot(x5, ax=axs[0][4])\n",
    "axs[0][4].set_title(\"Box plot of X5\")\n",
    "\n",
    "sns.boxplot(x6, ax=axs[0][5])\n",
    "axs[0][5].set_title(\"Box plot of X6\")\n",
    "\n",
    "sns.boxplot(x7, ax=axs[1][0])\n",
    "axs[1][0].set_title(\"Box plot of X7\")\n",
    "\n",
    "sns.boxplot(x8, ax=axs[1][1])\n",
    "axs[1][1].set_title(\"Box plot of X8\")\n",
    "\n",
    "sns.boxplot(x9, ax=axs[1][2])\n",
    "axs[1][2].set_title(\"Box plot of X9\")\n",
    "\n",
    "sns.boxplot(x10, ax=axs[1][3])\n",
    "axs[1][3].set_title(\"Box plot of X10\")\n",
    "\n",
    "sns.boxplot(x11, ax=axs[1][4])\n",
    "axs[1][4].set_title(\"Box plot of X11\")\n",
    "\n",
    "sns.boxplot(x12, ax=axs[1][5])\n",
    "axs[1][5].set_title(\"Box plot of X12\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPENDENT VARIABLE (Y) - AVG PRICE PER PLOT\n",
    "\n",
    "y = data1[\"Avg Price per sqft (in Rs.)\"]\n",
    "y\n",
    "\n",
    "# DENSITY PLOT OF Y\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "sns.distplot(y)\n",
    "axes.set_title(\"Density plot of Avg Price per sqft\")\n",
    "\n",
    "# NORMALITY CHECKING USING SHAPIRO WILK TEST\n",
    "\n",
    "stat1 , pvalue1 = scipy.stats.shapiro(y)\n",
    "print(stat1)\n",
    "print(pvalue1)\n",
    "\n",
    "if pvalue1<=0.05:\n",
    "    print(\"our data does not follow normal distribution\")\n",
    "else:\n",
    "    print(\"our data follows normal distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ PLOT\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "scipy.stats.probplot(y , dist = \"norm\" , plot = pylab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOXPLOT\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "sns.boxplot(x = y)\n",
    "axes.set_title(\"Box plot of Avg Price of plot per sq feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-Y RELATIONSHIP\n",
    "\n",
    "corr = data1.corr()\n",
    "corr\n",
    "\n",
    "sns.pairplot(corr)\n",
    "\n",
    "fig2,axes2 = plt.subplots(figsize=(8, 7))\n",
    "sns.heatmap(corr,annot=True, xticklabels= True , yticklabels= True , cmap=\"coolwarm\")\n",
    "axes2.set_title(\"Heatmap showing correlation between x and y values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION\n",
    "# ORIGINAL DATA FITTING - APPROACH 1\n",
    "\n",
    "\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x,y,test_size = 0.2, random_state = 3)\n",
    "\n",
    "model_1 = LinearRegression()\n",
    "model_1.fit(x_train1 , y_train1)\n",
    "\n",
    "model_1.score(x_test1 , y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZING THE MODEL\n",
    "\n",
    "fig, axs = plt.subplots(2,6, figsize=(30,9))\n",
    "\n",
    "sns.regplot(x=x1, y=y, data=data1, x_jitter=.05, ax=axs[0][0])\n",
    "axs[0][0].set_title(\"Model x1 vs y\")\n",
    "\n",
    "sns.regplot(x=x2, y=y, data=data1, x_jitter=.05, ax=axs[0][1])\n",
    "axs[0][1].set_title(\"Model x2 vs y\")\n",
    "\n",
    "sns.regplot(x=x3, y=y, data=data1, x_jitter=.05, ax=axs[0][2])\n",
    "axs[0][2].set_title(\"Model x3 vs y\")\n",
    "\n",
    "sns.regplot(x=x4, y=y, data=data1, ax=axs[0][3])\n",
    "axs[0][3].set_title(\"Model x4 vs y\")\n",
    "\n",
    "sns.regplot(x=x5, y=y, data=data1, x_jitter=.05, ax=axs[0][4])\n",
    "axs[0][4].set_title(\"Model x5 vs y\")\n",
    "\n",
    "sns.regplot(x=x6, y=y, data=data1, x_jitter=.05, ax=axs[0][5])\n",
    "axs[0][5].set_title(\"Model x6 vs y\")\n",
    "\n",
    "sns.regplot(x=x7, y=y, data=data1, x_jitter=.05, ax=axs[1][0])\n",
    "axs[1][0].set_title(\"Model x7 vs y\")\n",
    "\n",
    "sns.regplot(x=x8, y=y, data=data1, x_jitter=.05, ax=axs[1][1])\n",
    "axs[1][1].set_title(\"Model x8 vs y\")\n",
    "\n",
    "sns.regplot(x=x9, y=y, data=data1, x_jitter=.05, ax=axs[1][2])\n",
    "axs[1][2].set_title(\"Model x9 vs y\")\n",
    "\n",
    "sns.regplot(x=x10, y=y, data=data1, x_jitter=.05, ax=axs[1][3])\n",
    "axs[1][3].set_title(\"Model x10 vs y\")\n",
    "\n",
    "sns.regplot(x=x11, y=y, data=data1, x_jitter=.05, ax=axs[1][4])\n",
    "axs[1][4].set_title(\"Model x11 vs y\")\n",
    "\n",
    "sns.regplot(x=x12, y=y, data=data1, x_jitter=.05, ax=axs[1][5])\n",
    "axs[1][5].set_title(\"Model x12 vs y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "sns.jointplot(x=x1, y=y, data=data1, kind=\"reg\")\n",
    "sns.jointplot(x=x2, y=y, data=data1, kind=\"reg\")\n",
    "sns.jointplot(x=x3, y=y, data=data1, kind=\"reg\")\n",
    "sns.jointplot(x=x5, y=y, data=data1, kind=\"reg\")\n",
    "sns.jointplot(x=x6, y=y, data=data1, kind=\"reg\")\n",
    "sns.jointplot(x=x7, y=y, data=data1, kind=\"reg\")\n",
    "sns.jointplot(x=x8, y=y, data=data1, kind=\"reg\")\n",
    "sns.jointplot(x=x9, y=y, data=data1, kind=\"reg\")\n",
    "sns.jointplot(x=x10, y=y, data=data1, kind=\"reg\")\n",
    "sns.jointplot(x=x11, y=y, data=data1, kind=\"reg\")\n",
    "sns.jointplot(x=x12, y=y, data=data1, kind=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R SQUARED\n",
    "\n",
    "sklearn.metrics.r2_score(y_test1,y_pred_1)\n",
    "\n",
    "# Y TEST , PREDICTED Y\n",
    "\n",
    "y_pred_1 = model_1.predict(x_test1)\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "sns.distplot(y_test1)\n",
    "axes.set_title(\"Density plot of the original y values\")\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "sns.distplot(y_pred_1)\n",
    "axes.set_title(\"Density plot of the predicted y values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIDUALS\n",
    "\n",
    "residuals_1 = y_test1-y_pred_1\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "sns.distplot(residuals_1)\n",
    "axes.set_title(\"Density plot of the residual values\")\n",
    "\n",
    "# Y , Y^ , RES\n",
    "\n",
    "dict1 = {\"y values\" : y_test1 , \"Predicted y (y^)\" : y_pred_1 , \"Residuals (y-y^)\" : residuals_1}\n",
    "df1 = pd.DataFrame(dict1)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 FOLD CROSS VALIDATION SCORE\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores_1 =cross_val_score(model_1, x, y, cv=5)\n",
    "print(cv_scores_1)\n",
    "\n",
    "avg = np.mean(cv_scores_1)\n",
    "std = np.std(cv_scores_1)\n",
    "print(\"Average 5-Fold cross validation score - {}\".format(avg))\n",
    "print(\"Standard deviation - {}\".format(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse_1 = sqrt(mean_squared_error(y_test1, y_pred_1)) \n",
    "rmse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "***\n",
    "ASSUMPTIONS CHECK\n",
    "DATA DOES NOT FOLLOW NORMAL - ALREADY CHECKED THROUGH SHAPIRO WILK TEST , QQ PLOT AND BOX PLOT\n",
    "HOMOSKEDASTICITY NOT TRUE\n",
    "BP TEST\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libaries \n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "\n",
    "X = sm.add_constant(x_train1)\n",
    "mod = sm.OLS(y_train1,X)\n",
    "res = mod.fit()\n",
    "res.summary()\n",
    "\n",
    "#checking for heteroskedasticity\n",
    "names = ['Lagrange multiplier statistic', 'p-value',\n",
    "        'f-value', 'f p-value']\n",
    "test = sms.het_breuschpagan(res.resid, X)\n",
    "\n",
    "lzip(names, test)\n",
    "\n",
    "import statsmodels\n",
    "statsmodels.stats.diagnostic.het_goldfeldquandt(y_train1, x_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTED Y VS RES\n",
    "\n",
    "y1 = df1[\"Predicted y (y^)\"]\n",
    "e = df1[\"Residuals (y-y^)\"]\n",
    "\n",
    "plt.scatter(y1,e)\n",
    "plt.axhline(y=0)\n",
    "plt.xlabel(\"predicted y values\")\n",
    "plt.ylabel(\"residual values\")\n",
    "plt.title(\"Scatter plot of Predicted y vs Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTICOLLINEARITY EXISTS\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "x\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Independent Variables\"] = x.columns\n",
    "\n",
    "# calculating VIF for each independent variable\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(x.values, i)\n",
    "                          for i in range(len(x.columns))]\n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROACH 2 - REMOVING X COLUMNS WITH HIGH VIF , KEEPING Y THE SAME -  REGRESSION FIT\n",
    "\n",
    "x_new = x.drop([\"No of health care centers(Hospitals/Pharmacy)\",\"No of Educational Institutes\",\n",
    "                \"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\",\n",
    "                \"No of Restaurants\", \"No Religious Places(Temples/Mosques)\", \"No of Banks/ATMS\"] , axis = 1)\n",
    "y\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_new,y,test_size = 0.1, random_state = 3)\n",
    "\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(x_train2 , y_train2)\n",
    "model_2.score(x_test2 , y_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R SQUARED\n",
    "\n",
    "sklearn.metrics.r2_score(y_test2, y_pred_2)\n",
    "\n",
    "# Y TEST , PREDICTED Y\n",
    "\n",
    "y_pred_2 = model_2.predict(x_test2)\n",
    "y_pred_2\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "sns.distplot(y_test2)\n",
    "axes.set_title(\"Density plot of original y values\")\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "sns.distplot(y_pred_2)\n",
    "axes.set_title(\"Density plot of Predicted y values\")\n",
    "\n",
    "# RESIDUALS\n",
    "\n",
    "residuals_2 = y_test2-y_pred_2\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "sns.distplot(residuals_2)\n",
    "axes.set_title(\"Density plot of the residual values\")\n",
    "\n",
    "#Y , Y^ , RES\n",
    "\n",
    "dict1 = {\"y values\" : y_test2 , \"Predicted y (y^)\" : y_pred_2 , \"Residuals (y-y^)\" : residuals_2}\n",
    "df2 = pd.DataFrame(dict1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 FOLD CROSS VALIDATION SCORE\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores_2 =cross_val_score(model_2, x_new, y, cv=5)\n",
    "print(cv_scores_2)\n",
    "\n",
    "avg = np.mean(cv_scores_2)\n",
    "std = np.std(cv_scores_2)\n",
    "print(\"Average 5-Fold cross validation score - {}\".format(avg))\n",
    "print(\"Standard deviation - {}\".format(std))\n",
    "\n",
    "# RMSE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse_2 = sqrt(mean_squared_error(y_test2, y_pred_2))\n",
    "rmse_2\n",
    "\n",
    "\"\"\"##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRYING TO MAKE THE SCORE BETTER\n",
    "### APPROACH 3 - \n",
    "SCALED X(MINMAX SCALER) ; LOG(Y) -  REGRESSION FIT\n",
    "MINMAX X\n",
    "\n",
    "\n",
    "x\n",
    "\n",
    "scaler = preprocessing.RobustScaler()\n",
    "robust_df = scaler.fit_transform(x)\n",
    "robust_df = pd.DataFrame(robust_df , columns =[\"No. of metro stations\",\"No. of railway stations(<12kms)\",\n",
    "                                               \"No of bus stoppages\",\"Distance from the Airport(kms)\",\n",
    "                                               \"No of health care centers(Hospitals/Pharmacy)\",\"No of Educational Institutes\",\n",
    "                                               \"No of Departmental Stores\",\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\",\n",
    "                                               \"No of Restaurants\",\"No of Office\",\n",
    "                                               \"No Religious Places(Temples/Mosques)\",\"No of Banks/ATMS\"])\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standard_df = scaler.fit_transform(x)\n",
    "standard_df = pd.DataFrame(standard_df , columns =[\"No. of metro stations\",\"No. of railway stations(<12kms)\",\n",
    "                                               \"No of bus stoppages\",\"Distance from the Airport(kms)\",\n",
    "                                               \"No of health care centers(Hospitals/Pharmacy)\",\"No of Educational Institutes\",\n",
    "                                               \"No of Departmental Stores\",\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\",\n",
    "                                               \"No of Restaurants\",\"No of Office\",\n",
    "                                               \"No Religious Places(Temples/Mosques)\",\"No of Banks/ATMS\"])\n",
    " \n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "minmax_df = scaler.fit_transform(x)\n",
    "minmax_df = pd.DataFrame(minmax_df , columns =[\"No. of metro stations\",\"No. of railway stations(<12kms)\",\n",
    "                                               \"No of bus stoppages\",\"Distance from the Airport(kms)\",\n",
    "                                               \"No of health care centers(Hospitals/Pharmacy)\",\"No of Educational Institutes\",\n",
    "                                               \"No of Departmental Stores\",\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\",\n",
    "                                               \"No of Restaurants\",\"No of Office\",\n",
    "                                               \"No Religious Places(Temples/Mosques)\",\"No of Banks/ATMS\"])\n",
    " \n",
    "fig3,axes3 = plt.subplots(figsize=(20,6), nrows=1, ncols=4)\n",
    "\n",
    "axes3[0].set_title('Before Scaling')\n",
    "axes3[0].set_xlabel('X values')\n",
    "sns.kdeplot(x[\"No. of metro stations\"], ax = axes3[0], color ='red')\n",
    "sns.kdeplot(x[\"No. of railway stations(<12kms)\"], ax = axes3[0], color ='blue')\n",
    "sns.kdeplot(x[\"No of bus stoppages\"], ax = axes3[0], color ='green')\n",
    "sns.kdeplot(x[\"Distance from the Airport(kms)\"], ax = axes3[0], color ='yellow')\n",
    "sns.kdeplot(x[\"No of health care centers(Hospitals/Pharmacy)\"], ax = axes3[0], color ='purple')\n",
    "sns.kdeplot(x[\"No of Educational Institutes\"], ax = axes3[0], color ='black')\n",
    "sns.kdeplot(x[\"No of Departmental Stores\"], ax = axes3[0], color ='orange')\n",
    "sns.kdeplot(x[\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\"], ax = axes3[0], color ='pink')\n",
    "sns.kdeplot(x[\"No of Restaurants\"], ax = axes3[0], color ='cyan')\n",
    "sns.kdeplot(x[\"No of Office\"], ax = axes3[0], color ='maroon')\n",
    "sns.kdeplot(x[\"No Religious Places(Temples/Mosques)\"], ax = axes3[0], color ='brown')\n",
    "sns.kdeplot(x[\"No of Banks/ATMS\"], ax = axes3[0], color ='olive')\n",
    "\n",
    "\n",
    "axes3[1].set_title('After Robust Scaling')\n",
    "axes3[1].set_xlabel('X values')\n",
    "sns.kdeplot(robust_df[\"No. of metro stations\"], ax = axes3[1], color ='red')\n",
    "sns.kdeplot(robust_df[\"No. of railway stations(<12kms)\"], ax = axes3[1], color ='blue')\n",
    "sns.kdeplot(robust_df[\"No of bus stoppages\"], ax = axes3[1], color ='green')\n",
    "sns.kdeplot(robust_df[\"Distance from the Airport(kms)\"], ax = axes3[1], color ='yellow')\n",
    "sns.kdeplot(robust_df[\"No of health care centers(Hospitals/Pharmacy)\"], ax = axes3[1], color ='purple')\n",
    "sns.kdeplot(robust_df[\"No of Educational Institutes\"], ax = axes3[1], color ='black')\n",
    "sns.kdeplot(robust_df[\"No of Departmental Stores\"], ax = axes3[1], color ='orange')\n",
    "sns.kdeplot(robust_df[\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\"], ax = axes3[1], color ='pink')\n",
    "sns.kdeplot(robust_df[\"No of Restaurants\"], ax = axes3[1], color ='cyan')\n",
    "sns.kdeplot(robust_df[\"No of Office\"], ax = axes3[1], color ='maroon')\n",
    "sns.kdeplot(robust_df[\"No Religious Places(Temples/Mosques)\"], ax = axes3[1], color ='brown')\n",
    "sns.kdeplot(robust_df[\"No of Banks/ATMS\"], ax = axes3[1], color ='olive')\n",
    "\n",
    "axes3[2].set_title('After Standard Scaling')\n",
    "axes3[2].set_xlabel('X values')\n",
    "sns.kdeplot(standard_df[\"No. of metro stations\"], ax = axes3[2], color ='red')\n",
    "sns.kdeplot(standard_df[\"No. of railway stations(<12kms)\"], ax = axes3[2], color ='blue')\n",
    "sns.kdeplot(standard_df[\"No of bus stoppages\"], ax = axes3[2], color ='green')\n",
    "sns.kdeplot(standard_df[\"Distance from the Airport(kms)\"], ax = axes3[2], color ='yellow')\n",
    "sns.kdeplot(standard_df[\"No of health care centers(Hospitals/Pharmacy)\"], ax = axes3[2], color ='purple')\n",
    "sns.kdeplot(standard_df[\"No of Educational Institutes\"], ax = axes3[2], color ='black')\n",
    "sns.kdeplot(standard_df[\"No of Departmental Stores\"], ax = axes3[2], color ='orange')\n",
    "sns.kdeplot(standard_df[\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\"], ax = axes3[2], color ='pink')\n",
    "sns.kdeplot(standard_df[\"No of Restaurants\"], ax = axes3[2], color ='cyan')\n",
    "sns.kdeplot(standard_df[\"No of Office\"], ax = axes3[2], color ='maroon')\n",
    "sns.kdeplot(standard_df[\"No Religious Places(Temples/Mosques)\"], ax = axes3[2], color ='brown')\n",
    "sns.kdeplot(standard_df[\"No of Banks/ATMS\"], ax = axes3[2], color ='olive')\n",
    "\n",
    "axes3[3].set_title('After Min-Max Scaling')\n",
    "axes3[3].set_xlabel('X values')\n",
    "sns.kdeplot(minmax_df[\"No. of metro stations\"], ax = axes3[3], color ='red')\n",
    "sns.kdeplot(minmax_df[\"No. of railway stations(<12kms)\"], ax = axes3[3], color ='blue')\n",
    "sns.kdeplot(minmax_df[\"No of bus stoppages\"], ax = axes3[3], color ='green')\n",
    "sns.kdeplot(minmax_df[\"Distance from the Airport(kms)\"], ax = axes3[3], color ='yellow')\n",
    "sns.kdeplot(minmax_df[\"No of health care centers(Hospitals/Pharmacy)\"], ax = axes3[3], color ='purple')\n",
    "sns.kdeplot(minmax_df[\"No of Educational Institutes\"], ax = axes3[3], color ='black')\n",
    "sns.kdeplot(minmax_df[\"No of Departmental Stores\"], ax = axes3[3], color ='orange')\n",
    "sns.kdeplot(minmax_df[\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\"], ax = axes3[3], color ='pink')\n",
    "sns.kdeplot(minmax_df[\"No of Restaurants\"], ax = axes3[3], color ='cyan')\n",
    "sns.kdeplot(minmax_df[\"No of Office\"], ax = axes3[3], color ='maroon')\n",
    "sns.kdeplot(minmax_df[\"No Religious Places(Temples/Mosques)\"], ax = axes3[3], color ='brown')\n",
    "sns.kdeplot(minmax_df[\"No of Banks/ATMS\"], ax = axes3[3], color ='olive')\n",
    "\n",
    "minmax_df\n",
    "\n",
    "x1_m = minmax_df[\"No. of metro stations\"]\n",
    "x2_m = minmax_df[\"No. of railway stations(<12kms)\"]\n",
    "x3_m = minmax_df[\"No of bus stoppages\"]\n",
    "x4_m = minmax_df[\"Distance from the Airport(kms)\"]\n",
    "x5_m = minmax_df[\"No of health care centers(Hospitals/Pharmacy)\"]\n",
    "x6_m = minmax_df[\"No of Educational Institutes\"]\n",
    "x7_m = minmax_df[\"No of Departmental Stores\"]\n",
    "x8_m = minmax_df[\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\"]\n",
    "x9_m = minmax_df[\"No of Restaurants\"]\n",
    "x10_m = minmax_df[\"No of Office\"]\n",
    "x11_m = minmax_df[\"No Religious Places(Temples/Mosques)\"]\n",
    "x12_m = minmax_df[\"No of Banks/ATMS\"]\n",
    "\n",
    "fig, axs = plt.subplots(2,6, figsize=(20,6))\n",
    "\n",
    "sns.distplot(x1_m, ax=axs[0][0])\n",
    "axs[0][0].set_title(\"Density plot of Scaled X1\")\n",
    "\n",
    "sns.distplot(x2_m, ax=axs[0][1])\n",
    "axs[0][1].set_title(\"Density plot of Scaled X2\")\n",
    "\n",
    "sns.distplot(x3_m, ax=axs[0][2])\n",
    "axs[0][2].set_title(\"Density plot of Scaled X3\")\n",
    "\n",
    "sns.distplot(x4_m, ax=axs[0][3])\n",
    "axs[0][3].set_title(\"Density plot of Scaled X4\")\n",
    "\n",
    "sns.distplot(x5_m, ax=axs[0][4])\n",
    "axs[0][4].set_title(\"Density plot of Scaled X5\")\n",
    "\n",
    "sns.distplot(x6_m, ax=axs[0][5])\n",
    "axs[0][5].set_title(\"Density plot of Scaled X6\")\n",
    "\n",
    "sns.distplot(x7_m, ax=axs[1][0])\n",
    "axs[1][0].set_title(\"Density plot of Scaled X7\")\n",
    "\n",
    "sns.distplot(x8_m, ax=axs[1][1])\n",
    "axs[1][1].set_title(\"Density plot of Scaled X8\")\n",
    "\n",
    "sns.distplot(x9_m, ax=axs[1][2])\n",
    "axs[1][2].set_title(\"Density plot of Scaled X9\")\n",
    "\n",
    "sns.distplot(x10_m, ax=axs[1][3])\n",
    "axs[1][3].set_title(\"Density plot of Scaled X10\")\n",
    "\n",
    "sns.distplot(x11_m, ax=axs[1][4])\n",
    "axs[1][4].set_title(\"Density plot of Scaled X11\")\n",
    "\n",
    "sns.distplot(x12_m, ax=axs[1][5])\n",
    "axs[1][5].set_title(\"Density plot of Scaled X12\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG Y\n",
    "\n",
    "y_log = np.log10(y)\n",
    "y_log\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "\n",
    "sns.distplot(y_log)\n",
    "axes.set_title(\"Density plot of log y values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINMAX SCALED X & LOG Y -> ONE DATAFRAME\n",
    "\n",
    "y_log_df = pd.DataFrame(y_log)\n",
    "data2 = minmax_df.join(y_log_df , how = \"outer\")\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL FITTING\n",
    "\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(minmax_df,y_log_df,test_size = 0.1, random_state = 3)\n",
    "\n",
    "model_3 = LinearRegression()\n",
    "model_3.fit(x_train3 , y_train3)\n",
    "model_3.score(x_test3 , y_test3)\n",
    "\n",
    "y_pred3 = model_3.predict(x_test3)\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "sns.distplot(y_test3)\n",
    "axes.set_title(\"Density plot of original y values\")\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "sns.distplot(y_pred3)\n",
    "axes.set_title(\"Density plot of the Predicted y values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y & Y^\n",
    "\n",
    "index_ = y_test3.index\n",
    "y_new = pd.DataFrame(y_pred3 , index_ , [\"Predicted values\"])\n",
    "\n",
    "df4 = y_test3.join(y_new, how = \"outer\")\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIDUALS\n",
    "\n",
    "yt = df4[\"Avg Price per sqft (in Rs.)\"]\n",
    "yp = df4[\"Predicted values\"]\n",
    "\n",
    "res = yt - yp\n",
    "dict4 = {\"Residuals\":res}\n",
    "df5 = pd.DataFrame(dict4)\n",
    "\n",
    "df4.join(df5 , how=\"outer\")\n",
    "\n",
    "residuals = df5\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "axes = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "\n",
    "sns.distplot(residuals)\n",
    "axes.set_title(\"Density plot of Residual values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y^ VS RES\n",
    "\n",
    "plt.scatter(yp,res)\n",
    "plt.axhline(y=0)\n",
    "plt.xlabel(\"Predicted y values\")\n",
    "plt.ylabel(\"Residual values\")\n",
    "plt.title(\"Scatter plot of predicted values vs residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse_3 = sqrt(mean_squared_error(yt,yp)) \n",
    "rmse_3\n",
    "\n",
    "# RMSE COMPARISON BETWEEN THE 3 APPROACHES\n",
    "\n",
    "list1 = [\"Model 1 - x & y\" , \"Model 2 - Large vif dropped x & y\" , \"Model 1 - Minmax scaled x & log y\"]\n",
    "list2 = [rmse_1 , rmse_2 , rmse_3]\n",
    "\n",
    "dict2 = {\"Model\":list1 , \"RMSE Values\":list2}\n",
    "pd.DataFrame(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "#TURNING Y INTO A CATEGORICAL VARIABLE\n",
    "\n",
    "med_y = y.median()\n",
    "med_y\n",
    "\n",
    "y_list = []\n",
    "for i in y:\n",
    "    if i>med_y:\n",
    "        i=1\n",
    "    else:\n",
    "        i=0\n",
    "    y_list.append(i)\n",
    "    \n",
    "print(y_list)\n",
    "len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X & Y - DF\n",
    "\n",
    "d = {\"Avg Price per sqft in terms of HIGH and LOW price rating\" : y_list}\n",
    "\n",
    "y_list_df = pd.DataFrame(d)\n",
    "y_list_df\n",
    "\n",
    "DATA = x.join(y_list_df , how = \"outer\")\n",
    "DATA\n",
    "\n",
    "Y = DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING FREQUENCY AND PERCENTAGE FOR HIGH AND LOW\n",
    "\n",
    "a = Y.value_counts()\n",
    "b = Y.value_counts(normalize = True)\n",
    "print(b*100)\n",
    "\n",
    "a.plot(kind = \"bar\")\n",
    "plt.text(0,20,\"50.22 %\")\n",
    "plt.text(1,20,\"49.77 %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVARIATES AS PER HIGH AND LOW PRICE\n",
    "\n",
    "metro = pd.crosstab(x1,Y)\n",
    "metro.plot.bar()\n",
    "\n",
    "rail = pd.crosstab(x2,Y)\n",
    "rail.plot.bar()\n",
    "\n",
    "bus = pd.crosstab(x3,Y)\n",
    "bus.plot.bar()\n",
    "\n",
    "fig_1 = plt.figure(figsize=(15,5),dpi=100)\n",
    "\n",
    "x4_1 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 1][\"Distance from the Airport(kms)\"]\n",
    "x4_0 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 0][\"Distance from the Airport(kms)\"]\n",
    "\n",
    "\n",
    "x4_1 = np.array(x4_1)\n",
    "x4_0 = np.array(x4_0)\n",
    "\n",
    "plt.hist([x4_1 , x4_0] , bins = 30 , label = [\"Dist. from airport-high\" , \"Dist. from airport-low\"])\n",
    "plt.legend(loc = 1)\n",
    "\n",
    "x4.max()\n",
    "plt.xlim([0,250])\n",
    "plt.xlabel(\"Distance from the airport as per High and Low price rate\" )\n",
    "\n",
    "fig_1 = plt.figure(figsize=(15,5),dpi=100)\n",
    "\n",
    "x5_1 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 1][\"No of health care centers(Hospitals/Pharmacy)\"]\n",
    "x5_0 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 0][\"No of health care centers(Hospitals/Pharmacy)\"]\n",
    "\n",
    "\n",
    "x5_1 = np.array(x5_1)\n",
    "x5_0 = np.array(x5_0)\n",
    "\n",
    "plt.hist([x5_1 , x5_0] , bins = 30 , label = [\"Hospitals-high\" , \"Hospitals-low\"])\n",
    "plt.legend(loc = 1)\n",
    "\n",
    "x5.max()\n",
    "plt.xlim([0,500])\n",
    "plt.xlabel(\"Hospitals/Pharmacies as per High and Low price rate\" )\n",
    "\n",
    "fig_1 = plt.figure(figsize=(15,5),dpi=100)\n",
    "\n",
    "x6_1 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 1][\"No of Educational Institutes\"]\n",
    "x6_0 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 0][\"No of Educational Institutes\"]\n",
    "\n",
    "\n",
    "x6_1 = np.array(x4_1)\n",
    "x6_0 = np.array(x4_0)\n",
    "\n",
    "plt.hist([x6_1 , x6_0] , bins = 5 , label = [\"Edu In.-high\" , \"Edu In.-low\"])\n",
    "plt.legend(loc = 1)\n",
    "\n",
    "x6.max()\n",
    "plt.xlim([0,1850])\n",
    "plt.xlabel(\"Educational Institutes as per High and Low price rate\" )\n",
    "\n",
    "fig_1 = plt.figure(figsize=(15,5),dpi=100)\n",
    "\n",
    "x7_1 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 1][\"No of Departmental Stores\"]\n",
    "x7_0 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 0][\"No of Departmental Stores\"]\n",
    "\n",
    "\n",
    "x7_1 = np.array(x7_1)\n",
    "x7_0 = np.array(x7_0)\n",
    "\n",
    "plt.hist([x7_1 , x7_0] , bins = 30 , label = [\"Stores-high\" , \"Stores-low\"])\n",
    "plt.legend(loc = 1)\n",
    "\n",
    "x7.max()\n",
    "plt.xlim([0,200])\n",
    "plt.xlabel(\"Departmental Stores as per High and Low price rate\" )\n",
    "\n",
    "fig_1 = plt.figure(figsize=(15,5),dpi=100)\n",
    "\n",
    "x8_1 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 1][\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\"]\n",
    "x8_0 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 0][\"No of Recreational/ Entertainment Centres (Malls/Cinema Halls/Parks/Clubs)\"]\n",
    "\n",
    "\n",
    "x8_1 = np.array(x8_1)\n",
    "x8_0 = np.array(x8_0)\n",
    "\n",
    "plt.hist([x8_1 , x8_0] , bins = 30 , label = [\"Rec places-high\" , \"Rec places-low\"])\n",
    "plt.legend(loc = 1)\n",
    "\n",
    "x8.max()\n",
    "plt.xlim([0,750])\n",
    "plt.xlabel(\"Recreational places as per High and Low price rate\" )\n",
    "\n",
    "fig_1 = plt.figure(figsize=(15,5),dpi=100)\n",
    "\n",
    "x9_1 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 1][\"No of Restaurants\"]\n",
    "x9_0 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 0][\"No of Restaurants\"]\n",
    "\n",
    "\n",
    "x9_1 = np.array(x9_1)\n",
    "x9_0 = np.array(x9_0)\n",
    "\n",
    "plt.hist([x9_1 , x9_0] , bins = 30 , label = [\"Restaurants-high\" , \"Restaurants-low\"])\n",
    "plt.legend(loc = 1)\n",
    "\n",
    "x9.max()\n",
    "plt.xlim([0,1000])\n",
    "plt.xlabel(\"Restaurants as per High and Low price rate\" )\n",
    "\n",
    "fig_1 = plt.figure(figsize=(15,5),dpi=100)\n",
    "\n",
    "x10_1 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 1][\"No of Office\"]\n",
    "x10_0 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 0][\"No of Office\"]\n",
    "\n",
    "\n",
    "x10_1 = np.array(x10_1)\n",
    "x10_0 = np.array(x10_0)\n",
    "\n",
    "plt.hist([x10_1 , x10_0] , bins = 40 , label = [\"Offices-high\" , \"Offices-low\"])\n",
    "plt.legend(loc = 1)\n",
    "\n",
    "x10.max()\n",
    "plt.xlim([0,350])\n",
    "plt.xlabel(\"Offices as per High and Low price rate\" )\n",
    "\n",
    "fig_1 = plt.figure(figsize=(15,5),dpi=100)\n",
    "\n",
    "x11_1 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 1][\"No Religious Places(Temples/Mosques)\"]\n",
    "x11_0 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 0][\"No Religious Places(Temples/Mosques)\"]\n",
    "\n",
    "\n",
    "x11_1 = np.array(x11_1)\n",
    "x11_0 = np.array(x11_0)\n",
    "\n",
    "plt.hist([x11_1 , x11_0] , bins = 30 , label = [\"Religious places-high\" , \"Religious places-low\"])\n",
    "plt.legend(loc = 1)\n",
    "\n",
    "x11.max()\n",
    "plt.xlim([0,500])\n",
    "plt.xlabel(\"Religious places as per High and Low price rate\" )\n",
    "\n",
    "fig_1 = plt.figure(figsize=(15,5),dpi=100)\n",
    "\n",
    "x12_1 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 1][\"No of Banks/ATMS\"]\n",
    "x12_0 = DATA[DATA[\"Avg Price per sqft in terms of HIGH and LOW price rating\"] == 0][\"No of Banks/ATMS\"]\n",
    "\n",
    "\n",
    "x12_1 = np.array(x12_1)\n",
    "x12_0 = np.array(x12_0)\n",
    "\n",
    "plt.hist([x12_1 , x12_0] , bins = 30 , label = [\"Banks-high\" , \"Banks-low\"])\n",
    "plt.legend(loc = 1)\n",
    "\n",
    "x12.max()\n",
    "plt.xlim([0,450])\n",
    "plt.xlabel(\"Banks as per High and Low price rate\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION BETWEEN X AND Y\n",
    "\n",
    "corr = DATA.corr()\n",
    "\n",
    "sns.pairplot(corr)\n",
    "\n",
    "fig1,axes1 = plt.subplots(figsize=(8, 7))\n",
    "sns.heatmap(corr, annot = True, xticklabels= True , yticklabels= True , cmap=\"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY CLASSIFICATION\n",
    "# ON TESTING DATA\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y_list,test_size = 0.1, random_state = 3)\n",
    "\n",
    "model_3 = LogisticRegression()\n",
    "model_3.fit(x_train , y_train)\n",
    "model_3.score(x_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZING THE MODEL\n",
    "\n",
    "fig, axs = plt.subplots(2,6, figsize=(30,9))\n",
    "\n",
    "sns.regplot(x=x1, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[0][0])\n",
    "axs[0][0].set_title(\"Model x1 vs y\")\n",
    "\n",
    "sns.regplot(x=x2, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[0][1])\n",
    "axs[0][1].set_title(\"Model x2 vs y\")\n",
    "\n",
    "sns.regplot(x=x3, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[0][2])\n",
    "axs[0][2].set_title(\"Model x3 vs y\")\n",
    "\n",
    "sns.regplot(x=x4, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[0][3])\n",
    "axs[0][3].set_title(\"Model x4 vs y\")\n",
    "\n",
    "sns.regplot(x=x5, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[0][4])\n",
    "axs[0][4].set_title(\"Model x5 vs y\")\n",
    "\n",
    "sns.regplot(x=x6, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[0][5])\n",
    "axs[0][5].set_title(\"Model x6 vs y\")\n",
    "\n",
    "sns.regplot(x=x7, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[1][0])\n",
    "axs[1][0].set_title(\"Model x7 vs y\")\n",
    "\n",
    "sns.regplot(x=x8, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[1][1])\n",
    "axs[1][1].set_title(\"Model x8 vs y\")\n",
    "\n",
    "sns.regplot(x=x9, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[1][2])\n",
    "axs[1][2].set_title(\"Model x9 vs y\")\n",
    "\n",
    "sns.regplot(x=x10, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[1][3])\n",
    "axs[1][3].set_title(\"Model x10 vs y\")\n",
    "\n",
    "sns.regplot(x=x11, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[1][4])\n",
    "axs[1][4].set_title(\"Model x11 vs y\")\n",
    "\n",
    "sns.regplot(x=x12, y=y_list, data=DATA, logistic=True, ci=None,ax=axs[1][5])\n",
    "axs[1][5].set_title(\"Model x12 vs y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# INTERCEPT AND COEFFICIENTS\n",
    "\n",
    "print(\"The intercept term is\",model_3.intercept_)\n",
    "print(\"The coefficients are \")\n",
    "coeff = np.transpose(model_3.coef_)\n",
    "\n",
    "pd.DataFrame(coeff , x.columns , [\"Coefficients\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBABILITIES OF Y PREDICTED\n",
    "\n",
    "model_3.predict_proba(x_test)\n",
    "\n",
    "y_pred = model_3.predict(x_test)\n",
    "\n",
    "dict1 = {\"Original y values (y)\" : y_test , \"Predicted y values (y^)\" : y_pred}\n",
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 FOLD CROSS VALIDATION SCORE\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores_1 =cross_val_score(model_3, x, y_list, cv=5)\n",
    "print(cv_scores_1)\n",
    "\n",
    "avg = np.mean(cv_scores_1)\n",
    "std = np.std(cv_scores_1)\n",
    "print(\"Average 5-Fold cross validation score - {}\".format(avg))\n",
    "print(\"Standard deviation - {}\".format(std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 SCORE\n",
    "\n",
    "f1 = sklearn.metrics.f1_score(y_test, y_pred , average = \"weighted\")\n",
    "f1\n",
    "\n",
    "# CONFUSION MATRIX , CLASSIFICATION REPORT\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "print(classification_report)\n",
    "\n",
    "ConfMatrix = confusion_matrix(y_test,y_pred)\n",
    "print(ConfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING CONFUSION MATRIX\n",
    "\n",
    "sns.heatmap(ConfMatrix, annot = True , xticklabels = [\"No default\", \"Default\"], yticklabels = [\"No default\", \"Default\"])\n",
    "\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY , PRECISION , RECALL\n",
    "\n",
    "print(\"Accuracy - {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision - {}\".format(metrics.precision_score(y_test, y_pred,zero_division=1)))\n",
    "print(\"Recall - {}\".format(metrics.recall_score(y_test, y_pred,zero_division=0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC & AUC\n",
    "\n",
    "y_pred_probability = model_3.predict_proba(x_test)\n",
    "y_pred_probability = y_pred_probability[:,1]\n",
    "y_pred_probability\n",
    "\n",
    "auc_1 = metrics.roc_auc_score(y_test, y_pred_probability)\n",
    "auc_1\n",
    "\n",
    "# ROC CURVE\n",
    "\n",
    "fpr_1, tpr_1 , _ = metrics.roc_curve(y_test,  y_pred_probability)\n",
    "\n",
    "plt.plot(fpr_1,tpr_1,label=\"auc = {}\".format(auc_1))\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DATA\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y_list,test_size = 0.1, random_state = 3)\n",
    "\n",
    "model_3 = LogisticRegression()\n",
    "model_3.fit(x_train , y_train)\n",
    "model_3.score(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERCEPT AND COEFFICIENTS\n",
    "\n",
    "print(\"The intercept term is\",model_3.intercept_)\n",
    "print(\"The coefficients are \")\n",
    "coeff = np.transpose(model_3.coef_)\n",
    "pd.DataFrame(coeff , x.columns , [\"Coefficients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBABILITY OF Y PREDICTED\n",
    "\n",
    "model_3.predict_proba(x_train)\n",
    "\n",
    "# Y & Y^\n",
    "\n",
    "y_pred_train = model_3.predict(x_train)\n",
    "\n",
    "dict1 = {\"Original y values (y)\" : y_train , \"Predicted y values (y^)\" : y_pred_train}\n",
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 FOLD CROSS VALIDATION SCORE\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores_1 =cross_val_score(model_3, x, y_list, cv=5)\n",
    "print(cv_scores_1)\n",
    "\n",
    "avg = np.mean(cv_scores_1)\n",
    "std = np.std(cv_scores_1)\n",
    "print(\"Average 5-Fold cross validation score - {}\".format(avg))\n",
    "print(\"Standard deviation - {}\".format(std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 SCORE\n",
    "\n",
    "sklearn.metrics.f1_score(y_train, y_pred_train , average = \"weighted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICATION REPORT AND CONFUSION MATRIX\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classification_report = classification_report(y_train, y_pred_train)\n",
    "print(classification_report)\n",
    "\n",
    "ConfMatrix = confusion_matrix(y_train, y_pred_train)\n",
    "print(ConfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING CONFUSION MATRIX\n",
    "\n",
    "sns.heatmap(ConfMatrix, annot = True , xticklabels = [\"No default\", \"Default\"], yticklabels = [\"No default\", \"Default\"])\n",
    "\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY , PRECISION , RECALL\n",
    "\n",
    "print(\"Accuracy - {}\".format(metrics.accuracy_score(y_train, y_pred_train)))\n",
    "print(\"Precision - {}\".format(metrics.precision_score(y_train, y_pred_train)))\n",
    "print(\"Recall - {}\".format(metrics.recall_score(y_train, y_pred_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC & AUC\n",
    "\n",
    "y_pred_probability_train = model_3.predict_proba(x_train)\n",
    "y_pred_probability_train = y_pred_probability_train[:,1]\n",
    "y_pred_probability_train\n",
    "\n",
    "auc_1_train = metrics.roc_auc_score(y_train, y_pred_train)\n",
    "auc_1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC CURVE\n",
    "\n",
    "fpr_1_train, tpr_1_train , _ = metrics.roc_curve(y_train,  y_pred_probability_train)\n",
    "\n",
    "plt.plot(fpr_1_train, tpr_1_train,label=\"auc = {}\".format(auc_1_train))\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC CURVE FOR TESTING AND TRAINING DATASET\n",
    "\n",
    "fig_1 = plt.figure(figsize=(5,5),dpi=100)\n",
    "axes_1 = fig_1.add_axes([0.1,0.1,0.9,0.9])\n",
    "\n",
    "\n",
    "axes_1.set_title(\"Roc curve for training and testing data\")\n",
    "\n",
    "axes_1.plot(fpr_1,tpr_1,label=\"auc = {}\".format(auc_1)) \n",
    "\n",
    "axes_1.plot(fpr_1_train, tpr_1_train,label=\"auc = {}\".format(auc_1_train))         \n",
    "axes_1.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRATREESCLASSIFIER\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x,y_list)\n",
    "\n",
    "#use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "\n",
    "feat_importances = pd.Series(model.feature_importances_, index=x.columns)\n",
    "print(feat_importances.sort_values(ascending=False).cumsum())\n",
    "feat_importances.nlargest(12).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTICLASS\n",
    "\n",
    "y\n",
    "\n",
    "q1 = np.percentile(y,25)\n",
    "q2 = np.percentile(y,50)\n",
    "q3 = np.percentile(y,75)\n",
    "\n",
    "print(\"The quantiles of y are ->\")\n",
    "print(\"Q1 : {} , Q2 : {} , Q3 : {}\".format(q1,q2,q3))\n",
    "\n",
    "y_list2 = []\n",
    "for i in y:\n",
    "    if i<=q1:\n",
    "        i=0\n",
    "    elif (i>q1) and (i<q3):\n",
    "        i=1\n",
    "    else:\n",
    "        i=2\n",
    "    y_list2.append(i)\n",
    "    \n",
    "print(y_list2)\n",
    "len(y_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON TESTING DATA\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y_list2,test_size = 0.1, random_state = 1)\n",
    "\n",
    "model_4 = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\")\n",
    "model_4.fit(x_train , y_train)\n",
    "model_4.score(x_test , y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERCEPT AND COEFFICIENTS\n",
    "\n",
    "print(\"The intercept term is\",model_4.intercept_)\n",
    "print(\"The coefficients are \")\n",
    "\n",
    "coeff2 = np.transpose(model_4.coef_)\n",
    "\n",
    "pd.DataFrame(coeff2 , x.columns , [\"For class 0\", \"For class 1\", \"For class 2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y , Y^\n",
    "\n",
    "y_pred = model_4.predict(x_test)\n",
    "\n",
    "dict1 = {\"Original y values (y)\" : y_test , \"Predicted y values (y^)\" : y_pred}\n",
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 FOLD CROSS VALIDATION SCORE\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores_1 =cross_val_score(model_4, x, y_list, cv=5)\n",
    "print(cv_scores_1)\n",
    "\n",
    "avg = np.mean(cv_scores_1)\n",
    "std = np.std(cv_scores_1)\n",
    "print(\"Average 5-Fold cross validation score - {}\".format(avg))\n",
    "print(\"Standard deviation - {}\".format(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 SCORE\n",
    "\n",
    "sklearn.metrics.f1_score(y_test, y_pred , average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSFICATION REPORT & CONFUSION MATRIX\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "print(classification_report)\n",
    "\n",
    "ConfMatrix = confusion_matrix(y_test,y_pred)\n",
    "print(ConfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING THE CONFUSION MATRIX\n",
    "\n",
    "sns.heatmap(ConfMatrix, annot = True , xticklabels = [\"No default\", \"Default\"], yticklabels = [\"No default\", \"Default\"])\n",
    "\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY , PRECISION , RECALL\n",
    "\n",
    "print(\"Accuracy - {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision - {}\".format(metrics.precision_score(y_test, y_pred , average = \"weighted\")))\n",
    "print(\"Recall - {}\".format(metrics.recall_score(y_test, y_pred , average = \"weighted\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "\n",
    "y_pred_probability = model_4.predict_proba(x_test)\n",
    "y_pred_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC\n",
    "\n",
    "auc_1 = metrics.roc_auc_score(y_test, y_pred_probability,multi_class = \"ovo\")\n",
    "auc_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON TRAINING DATA\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y_list2,test_size = 0.1, random_state = 1)\n",
    "\n",
    "model_4 = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\")\n",
    "model_4.fit(x_train , y_train)\n",
    "model_4.score(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERCEPT AND COEFFICIENTS\n",
    "\n",
    "print(\"The intercept term is\",model_4.intercept_)\n",
    "print(\"The coefficients are \")\n",
    "\n",
    "coeff2 = np.transpose(model_4.coef_)\n",
    "\n",
    "pd.DataFrame(coeff2 , x.columns , [\"For class 0\", \"For class 1\", \"For class 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y & Y^\n",
    "\n",
    "y_pred_train = model_4.predict(x_train)\n",
    "\n",
    "dict1 = {\"Original y values (y)\" : y_train , \"Predicted y values (y^)\" : y_pred_train}\n",
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 FOLD CROSS VALIDATION SCORE\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores_1 =cross_val_score(model_4, x, y_list, cv=5)\n",
    "print(cv_scores_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.mean(cv_scores_1)\n",
    "std = np.std(cv_scores_1)\n",
    "print(\"Average 5-Fold cross validation score - {}\".format(avg))\n",
    "print(\"Standard deviation - {}\".format(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 SCORE\n",
    "\n",
    "sklearn.metrics.f1_score(y_train, y_pred_train , average = \"weighted\")\n",
    "\n",
    "# CLASSIFICATION REPORT AND CONFUSION MATRIX\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classification_report = classification_report(y_train, y_pred_train)\n",
    "print(classification_report)\n",
    "\n",
    "ConfMatrix = confusion_matrix(y_train, y_pred_train)\n",
    "print(ConfMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING THE CONFUSION MATRIX\n",
    "\n",
    "sns.heatmap(ConfMatrix, annot = True , xticklabels = [\"No default\", \"Default\"], yticklabels = [\"No default\", \"Default\"])\n",
    "\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY, PRECISION, RECALL\n",
    "\n",
    "print(\"Accuracy - {}\".format(metrics.accuracy_score(y_train, y_pred_train)))\n",
    "print(\"Precision - {}\".format(metrics.precision_score(y_train, y_pred_train , average = \"weighted\")))\n",
    "print(\"Recall - {}\".format(metrics.recall_score(y_train, y_pred_train , average = \"weighted\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "\n",
    "y_pred_probability_train = model_4.predict_proba(x_train)\n",
    "y_pred_probability_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC\n",
    "\n",
    "auc_1 = metrics.roc_auc_score(y_train, y_pred_probability_train,multi_class = \"ovo\")\n",
    "auc_1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
